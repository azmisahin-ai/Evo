# config/main_config.yaml
# Evo Projesi Ana Yapılandırma Dosyası

# Genel Ayarlar
cognitive_loop_interval: 0.03 # Daha hızlı tepki için deneyelim, AE GPU'da olmalı

# Hesaplama Ayarları
compute:
  backend: "pytorch"
  device: "cuda"

# Sense Modülleri Ayarları
vision:
  # source_type: "usb_camera" | "ip_camera" | "video_file" | "image_folder" | "screen_capture"
  source_type: "ip_camera"

  # Eğer source_type: "usb_camera" ise:
  camera_index: 0 # Kullanılacak USB kamera indeksi (0, 1, 2...)

  ip_camera_url: "http://192.168.1.84:8080/video"

 # Eğer source_type: "video_file" ise:
  video_file_path: "data/videos/test_video.mp4" # Video dosyasının yolu
  loop_video: True # Video bittiğinde başa sarsın mı?

  # Eğer source_type: "image_folder" ise (Daha karmaşık implementasyon gerektirir):
  # image_folder_path: "data/image_sequence/"
  # image_file_pattern: "frame_%04d.png" # Örn: frame_0001.png, frame_0002.png
  # image_sequence_fps: 10 # Saniyede kaç kare okunacağı

  # Eğer source_type: "screen_capture" ise (Platforma özel kütüphane gerektirebilir):
  # screen_capture_region: null # null ise tüm ekran, veya [x, y, width, height]
  
  is_dummy: False
  process_color: True # VisionProcessor renkli (True) mi gri (False) mi işlesin?
  # Dummy ayarları sadece is_dummy: True ise kullanılır.
  dummy_width: 640
  dummy_height: 480

audio:
  audio_rate: 44100
  audio_chunk_size: 1024
  audio_input_device_index: null
  is_dummy: False

# Processor Modülleri Ayarları
processors:
  vision:
    output_width: 64  # Yeniden boyutlandırılacak ana görüntü ve kenar haritası için
    output_height: 64
    # output_channels, VisionSensor.process_color'a göre VisionProcessor'da belirlenir.
    # Bu ayar, module_loader'ın input_dim hesaplamasında referans olabilir.
    output_channels_main_image: 3 # process_color:True ise 3 (RGB), False ise 1 (Gri)
    enable_edge_detection: True # Kenar tespiti aktif mi? TRUE?
    gaussian_blur_kernel_size: "5,5" # Kenar tespiti öncesi Gaussian Blur kernel boyutu (tek_sayi,tek_sayi)
    canny_low_threshold: 70          # Canny düşük eşiği (gürültüye göre ayarlayın)
    canny_high_threshold: 190        # Canny yüksek eşiği (gürültüye göre ayarlayın)
    use_gpu_if_available: True       # OpenCV sonrası tensörler GPU'ya taşınsın mı? (PyTorch backend için)
  audio:
    output_dim: 2 # Enerji ve Spektral Sentroid
    audio_rate: 44100

# Representation Learner (Autoencoder) Ayarları
representation:
  input_dim: "auto"    # Sadece main_image (12288) + audio (2) = 12290 olacak
  representation_dim: 128     # <<< Daha küçük bir latent boyut : 64, 128, 256
  hidden_dim_ae: 1024       # <<< Daha küçük bir gizli katman 512 (veya 256, 1024).
  learning_rate: 0.0002    # <<< Daha agresif bir öğrenme oranı 1e-3 (0.001), 5e-4 (0.0005), 1e-4 (0.0001), 5e-5 (0.00005)

# Memory Modülleri Ayarları
memory:
  max_working_memory_size: 100  # <<< LTM'ye daha hızlı transfer için : Kısa süreli/çalışma belleği için daha küçük bir boyut
  num_retrieved_working_memories: 5 
  
  # Uzun Süreli Bellek (LTM) Ayarları - Episodik ve/veya Semantik için temel
  enable_ltm_persistence: True      # <<< YENİ: LTM'yi dosyaya kaydet/yükle
  ltm_file_path: "data/evo_ltm.pkl" # <<< YENİ: Uzun süreli anılar için ayrı bir dosya
  max_ltm_size: 2000                # <<< YENİ: LTM için daha büyük bir kapasite (isteğe bağlı)

# Cognition Modülleri Ayarları
cognition:
  familiarity_threshold: 0.70 # Yüksek bir değer, sadece çok benzerleri "tanıdık" sayar.
  concept_recognition_threshold: 0.75 # Tanıdık eşiğinden biraz daha yüksek.
  audio_energy_threshold: 1000.0
  visual_edges_threshold: 0.15 # Eğer kenarlar normalize ise, bu eşik daha anlamlı olabilir
                               # Eğer kenarlar 0/255 ise, bu değer 20-50 gibi olmalı. VisionProcessor çıktısına bağlı.
  brightness_threshold_high: 200.0
  brightness_threshold_low: 50.0
  curiosity_threshold: 3.5          # Daha kolay meraklan
  curiosity_increment_new: 1.2      # Yeniye daha çok merak
  curiosity_decrement_familiar: 0.5  # Tanıdıktan daha az sıkıl
  curiosity_decay: 0.03           # Merak daha yavaş azalsın
  learning:
    enable_concept_persistence: True  # <<< YENİ: Öğrenilen kavramları dosyaya kaydet/yükle
    concept_file_path: "data/evo_concepts_final.pkl" # Bu zaten vardı, enable ile kontrol edilecek
    learning_frequency: 15          # <<< Seyrekleştirdik
    learning_memory_sample_size: 10   # <<< Artırdık
    new_concept_threshold: 0.70 # Latent temsiller için (max_sim < 0.70 ise YENİ)

# Motor Control Modülleri Ayarları
motor_control:
  expression: {}

# Interaction Modülleri Ayarları
interaction:
  enabled_channels:
    - console
  channel_configs:
    console: {}

# Loglama Ayarları
logging:
  level: INFO 
  handlers:
    - type: console
      level: INFO   
      color: true
    - type: file
      filename: logs/evo_test_simple_ae.log 
      level: DEBUG            
      color: false
  modules:
    src.memory.core: DEBUG          # <<< LTM'ye geçişleri görmek için
    src.cognition.learning: DEBUG   # <<< Kavram öğrenme detayları için
    src.representation.models: DEBUG # <<< AE kaybı için
    src.cognition.understanding: DEBUG # <<< Benzerlik skorları için
    __main__: DEBUG                     # RUN_EVO_COSINE logları için

debug:
  show_camera_feed: True           # Ham kamera görüntüsünü göster (True/False)
  show_processed_main_image: False  # VisionProcessor'dan çıkan ana işlenmiş görüntüyü göster (True/False)
  show_processed_edges_image: False   # VisionProcessor'dan çıkan kenar görüntüsünü göster (True/False)
   # log_level_override: DEBUG     # Gelecekte, ana log seviyesini buradan override etmek için
  # cognitive_loop_break_after: 0 # 0 ise normal çalışır, >0 ise o kadar döngüden sonra durur (test için)